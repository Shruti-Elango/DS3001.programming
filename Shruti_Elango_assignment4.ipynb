{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shruti-Elango/DS3001.programming/blob/Finished-Assignments/Shruti_Elango_assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac",
      "metadata": {
        "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac"
      },
      "source": [
        "# Assignment #4: Linear Models and Decision Trees\n",
        "## Foundations of Machine Learning\n",
        "## Do Q1 and one other question.\n",
        "### Advice: Reuse your code and code from lectures, package routine tasks into functions, make plans about how you'll carry out the analysis before jumping into writing code, and work as efficiently as possible"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( 'Questions completed 1 and 4')\n",
        "print('Shruti Elango (se2ezr)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMvA-L5mz6Ab",
        "outputId": "96cf6936-b7ae-4e20-f046-0676c93eeca2"
      },
      "id": "yMvA-L5mz6Ab",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Questions completed 1 and 4\n",
            "Shruti Elango (se2ezr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b",
      "metadata": {
        "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b"
      },
      "source": [
        "**Q1.** This question is a case study for linear models and decision trees. The data are about car prices. In particular, they include:\n",
        "\n",
        "  - `Price`, `Color`, `Seating_Capacity`\n",
        "  - `Body_Type`: crossover, hatchback, muv, sedan, suv\n",
        "  - `Make`, `Make_Year`: The brand of car and year produced\n",
        "  - `Mileage_Run`: The number of miles on the odometer\n",
        "  - `Fuel_Type`: Diesel or gasoline/petrol\n",
        "  - `Transmission`, `Transmission_Type`:  speeds and automatic/manual\n",
        "\n",
        "  1. Load `cars_hw.csv`. These data were really dirty, and I've already cleaned them a significant amount in terms of missing values and other issues, but some issues remain (e.g. outliers, badly scaled variables that require a log or arcsinh transformation). Clean the data however you think is most appropriate.\n",
        "  2. Summarize the `Price` variable and create a kernel density plot. Use `.groupby()` and `.describe()` to summarize prices by brand (`Make`). Make a grouped kernel density plot by `Make`. Which car brands are the most expensive? What do prices look like in general?\n",
        "  3. Split the data into an 80% training set and a 20% testing set.\n",
        "  4. Let's focus on linear models. Make a model where you regress price on the numeric variables alone; what is the $R^2$ and `RMSE` on the test set? Make a second model where, for the categorical variables, make a model comprised of one-hot encoded regressors/features alone, and regress price on those variables; what is the $R^2$ and `RMSE` on the test set? Which model performs better on the test set? Make a third model that combines all the regressors from the previous two; what is the $R^2$ and `RMSE` on the test set? Does the joint model perform better or worse, and by home much?\n",
        "  5. Use the `PolynomialFeatures` function from `sklearn` to expand the set of numerical variables you're using, along with the categorical variables. As you increase the degree of the expansion, how do the $R^2$ and `RMSE` change? At what point does $R^2$ go negative on the test set? For your best model with expanded features, what is the $R^2$ and `RMSE`? How does it compare to your best model from part 3?\n",
        "  6. For your best model so far, determine the predicted values for the test data and plot them against the true values. Do the predicted values and true values roughly line up along the diagonal, or not? Compute the residuals/errors for the test data and create a kernel density plot. Do the residuals look roughly bell-shaped around zero? Evaluate the strengths and weaknesses of your model.\n",
        "  7. Now, let's use a regression tree. Construct an appropriate matrix of regressors/features, and fit a tree to the data. Vary the maximum depth of the decision tree using the `max_depth` option (i.e. `tree.DecisionTreeRegressor(max_depth=D)`), and compute the $R^2$ and `RMSE` on the test set of a variety of depths. What depth tree gives the best results?\n",
        "  8. For your best tree, determine the predicted values for the test data, and plot them against the true values. Do the predicted values and true values line up along the diagonal, or not? Compute the residuals/errors for the test data and create a kernel density plot. Do the residuals look roughly bell-shaped around zero?\n",
        "  12. Which model --- linear model or classification and regression tree --- has better performance on the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d",
      "metadata": {
        "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d"
      },
      "source": [
        "**Q2.** The is a question about regression using decision trees and linear models. The data include wages at data science-y jobs, including\n",
        "\n",
        "  - `Rating`: Company worker happiness score\n",
        "  - `Size`: Number of employees\n",
        "  - `Sector`: Part of the economy\n",
        "  - `avg_salary`: Average wage\n",
        "  - `job_state`: Location of work\n",
        "\n",
        "  1. Load the `wages_hw.csv` file. Split the sample into an ~80% training set and a ~20% test set. Do any necessary cleaning, including outliers and missings.\n",
        "  2. Use a linear model to regress `avg_salary` on `Sector`. Which sectors have the highest predicted wages? What is the $R^2$ and `RMSE` on the test set?\n",
        "  3. Make a scatterplot of `avg_salary` and `Rating`. Is there an obvious visual relationship between the two variables? Regress `avg_salary` on `Rating` as a numeric variable: Do higher ratings predict higher or lower wages? Convert `Rating` to a one-hot encoded variable, with a category for each rating. Run a regression of `avg_salary` on the categorical version. How do your results change? Explain. Which version has a higher $R^2$ and lower `RMSE`?\n",
        "  4. Now interact `Sector` with the categorical version of `Rating`, so your regressors are a (Sector, Rating) pair; this is a programming puzzle you'll have to think about, but using the `.PolynomialFeatures()` function on the one-hot encoded categorical variables is one option, and another is pre-processing a new variable that interacts `Sector` and `Rating` and then one-hot encoding the result. Regress `avg_salary` on the (Sector, Rating) pairs. How does the $R^2$ and `RMSE` on the test set compare to part 2? Interpret the coefficients; which sector-rating pairs have the highest wages?\n",
        "  5. Run a linear regression of `avg_salary` on all the variables. What is the $R^2$ on the test set? How does it compare to your simpler models in 2--4?\n",
        "  6. Build a decision tree by regressing `avg_salary` on `Sector`, `Rating`, and the (Sector, Rating) pairs. What are the $R^2$ and `RMSE` of your models on the test set? How do your answers compare to parts 2, 3, and 4?\n",
        "  7. Build a decision tree by regressing `avg_salary` on all the other variables. What is the $R^2$ and `RMSE` on the test set?\n",
        "  8. Build a linear regression or decision tree using the available variables based on your own judgment. What degrees of freedom are you giving the model to predict variation in wages across company and location attributes? What is the $R^2$ and `RMSE` of your model? How does it compare to the previous ones in the question? Why does yours perform better or worse on the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "409519b9-e803-4a95-aded-d6eabf6bc526",
      "metadata": {
        "id": "409519b9-e803-4a95-aded-d6eabf6bc526"
      },
      "source": [
        "**Q3.** This a question purely on categorical prediction. The data for this happen to be gathered in 1987 in Indonesia, and concern contraceptive method choice. The questions and data-gathering assumptions reflect the culture and attitudes of that time and place, but provide a good example of a categorical prediction problem on an important topic (family planning and maternal health The variables in the data are:\n",
        "\n",
        "    - Wife's age (numerical)\n",
        "    - Wife's education (categorical) 1=low, 2, 3, 4=high\n",
        "    - Husband's education (categorical) 1=low, 2, 3, 4=high\n",
        "    - Number of children ever born (numerical)\n",
        "    - Wife's religion (binary) 0=Non-Islam, 1=Islam\n",
        "    - Wife's now working? (binary) 0=Yes, 1=No\n",
        "    - Husband's occupation (categorical) 1, 2, 3, 4\n",
        "    - Standard-of-living index (categorical) 1=low, 2, 3, 4=high\n",
        "    - Media exposure (binary) 0=Good, 1=Not good\n",
        "    - Contraceptive method used (class attribute) 1=No-use, 2=Long-term, 3=Short-termhort-term\n",
        "\n",
        "  1. Load the `contraceptiveMethodChoice.csv` data. Tabulate the `method` variable (i.e. `.value_counts()`). 1 corresponds to `No Contraception`, 3 corresponds to `Short Term` (e.g. condoms, birth control pills), and 2 corresponds to `Long Term` (e.g. IUD, sterilization). Cross tabulate `method` and `numberChildren`. Do couples that use birth control tend to have more children than those who don't?\n",
        "  2. Split the sample into ~80% training data and ~20% testing data.\n",
        "  3. We are now going to make a mistake. Train a regression tree to predict the contraceptive method using the other variables in the data, not a classification tree. Look at the terminal nodes in the tree: What values do they take? Does that make sense? Explain clearly what has gone wrong here.\n",
        "  4. Instead of regression, use a classification tree to predict contraceptive method using the other variables in the data. How does it look different from the previous tree? What variables does the algorithm use? In broad terms, which groups of people are most likely to use each method of contraception?\n",
        "  5. Compute a confusion matrix for your classification tree on the test set (Hint: There are now three categories instead of two, so the cross tabulation will be a $3 \\times 3$ matrix instead of $2 \\times 2$.). Compute the Accuracy of your model overall, and the Accuracy for predicting each contraceptive method.\n",
        "  7. Why can't you use a linear probability model to do this exercise? Explain clearly in words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "!pip install pandas\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCcMxhQ8j7FJ",
        "outputId": "9d151f97-f5a8-402b-d453-26ad1b4d9a88"
      },
      "id": "HCcMxhQ8j7FJ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/contraception_hw.csv')\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "CJlBR4CWkofP",
        "outputId": "c92de6c9-9772-4169-d7fa-1c6e65f0bea1"
      },
      "id": "CJlBR4CWkofP",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0          age          edu   edu_spouse  numberChildren  \\\n",
              "count  1473.000000  1473.000000  1473.000000  1473.000000     1473.000000   \n",
              "mean    737.000000    32.538357     2.958588     3.429735        3.261371   \n",
              "std     425.362786     8.227245     1.014994     0.816349        2.358549   \n",
              "min       1.000000    16.000000     1.000000     1.000000        0.000000   \n",
              "25%     369.000000    26.000000     2.000000     3.000000        1.000000   \n",
              "50%     737.000000    32.000000     3.000000     4.000000        3.000000   \n",
              "75%    1105.000000    39.000000     4.000000     4.000000        4.000000   \n",
              "max    1473.000000    49.000000     4.000000     4.000000       16.000000   \n",
              "\n",
              "          religion      working  spouse_occupation  standardOfLivingIndex  \\\n",
              "count  1473.000000  1473.000000        1473.000000            1473.000000   \n",
              "mean      0.850645     0.749491           2.137814               3.133741   \n",
              "std       0.356559     0.433453           0.864857               0.976161   \n",
              "min       0.000000     0.000000           1.000000               1.000000   \n",
              "25%       1.000000     0.000000           1.000000               3.000000   \n",
              "50%       1.000000     1.000000           2.000000               3.000000   \n",
              "75%       1.000000     1.000000           3.000000               4.000000   \n",
              "max       1.000000     1.000000           4.000000               4.000000   \n",
              "\n",
              "       mediaExposure       method  \n",
              "count    1473.000000  1473.000000  \n",
              "mean        0.073999     1.919891  \n",
              "std         0.261858     0.876376  \n",
              "min         0.000000     1.000000  \n",
              "25%         0.000000     1.000000  \n",
              "50%         0.000000     2.000000  \n",
              "75%         0.000000     3.000000  \n",
              "max         1.000000     3.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3057b7d4-9c15-46c7-8ee4-3f0e9d78b6ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>edu</th>\n",
              "      <th>edu_spouse</th>\n",
              "      <th>numberChildren</th>\n",
              "      <th>religion</th>\n",
              "      <th>working</th>\n",
              "      <th>spouse_occupation</th>\n",
              "      <th>standardOfLivingIndex</th>\n",
              "      <th>mediaExposure</th>\n",
              "      <th>method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "      <td>1473.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>737.000000</td>\n",
              "      <td>32.538357</td>\n",
              "      <td>2.958588</td>\n",
              "      <td>3.429735</td>\n",
              "      <td>3.261371</td>\n",
              "      <td>0.850645</td>\n",
              "      <td>0.749491</td>\n",
              "      <td>2.137814</td>\n",
              "      <td>3.133741</td>\n",
              "      <td>0.073999</td>\n",
              "      <td>1.919891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>425.362786</td>\n",
              "      <td>8.227245</td>\n",
              "      <td>1.014994</td>\n",
              "      <td>0.816349</td>\n",
              "      <td>2.358549</td>\n",
              "      <td>0.356559</td>\n",
              "      <td>0.433453</td>\n",
              "      <td>0.864857</td>\n",
              "      <td>0.976161</td>\n",
              "      <td>0.261858</td>\n",
              "      <td>0.876376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>369.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>737.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1105.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1473.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3057b7d4-9c15-46c7-8ee4-3f0e9d78b6ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3057b7d4-9c15-46c7-8ee4-3f0e9d78b6ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3057b7d4-9c15-46c7-8ee4-3f0e9d78b6ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1b78340-0d77-4d6b-bd63-f6fcc269dd86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1b78340-0d77-4d6b-bd63-f6fcc269dd86')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1b78340-0d77-4d6b-bd63-f6fcc269dd86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "# Replace values in the 'method' column with their corresponding categories\n",
        "method_mapping = {1: \"No Contraception\", 3: \"Short Term\", 2: \"Long Term\"}\n",
        "df['method'] = df['method'].map(method_mapping)\n",
        "\n",
        "# Now, let's tabulate the 'method' variable.\n",
        "method_counts = df['method'].value_counts()\n",
        "\n",
        "# Cross-tabulate 'method' and 'numberChildren' variables.\n",
        "cross_tab = pd.crosstab(df['method'], df['numberChildren'])\n",
        "\n",
        "# Display the tabulated results\n",
        "print(\"Method Variable Counts:\")\n",
        "print(method_counts)\n",
        "print(\"\\nCross-Tabulation of Method and numberChildren:\")\n",
        "print(cross_tab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh3zjMIRlpmi",
        "outputId": "ff46bb2d-9a8c-456f-e4b7-fbdf6c61e785"
      },
      "id": "zh3zjMIRlpmi",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method Variable Counts:\n",
            "No Contraception    629\n",
            "Short Term          511\n",
            "Long Term           333\n",
            "Name: method, dtype: int64\n",
            "\n",
            "Cross-Tabulation of Method and numberChildren:\n",
            "numberChildren    0    1    2    3   4   5   6   7   8   9   10  11  12  13  \\\n",
            "method                                                                        \n",
            "Long Term          0   46   56   70  62  36  27  19   9   3   2   2   0   1   \n",
            "No Contraception  95  143  114   70  57  44  35  18  29   5   9   6   4   0   \n",
            "Short Term         2   87  106  119  78  55  30  12   9   8   0   3   0   1   \n",
            "\n",
            "numberChildren    16  \n",
            "method                \n",
            "Long Term          0  \n",
            "No Contraception   0  \n",
            "Short Term         1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define your features (X) and target variable (y)\n",
        "X = df.drop(columns=['method'])\n",
        "y = df['method']\n",
        "\n",
        "# Split the data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0xycmftqmZpx"
      },
      "id": "0xycmftqmZpx",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Decision Trees sample code:\n",
        "from sklearn import tree\n",
        "\n",
        "model = tree.DecisionTreeClassifier(max_depth=10) # Fit the classifier\n",
        "cart = model.fit(X_train, y_train)\n",
        "tree.plot_tree(cart,filled=True)\n",
        "\n",
        "## Make Predictions on the Test Set\n",
        "y_hat_cart = cart.predict(X_test)\n",
        "\n",
        "# Compute performance:\n",
        "perf_cart = performance(y_test,y_hat_cart)\n",
        "print(perf_cart)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "nceqdadgnW7P",
        "outputId": "3e22840a-39cd-4e57-f33b-f35bec303806"
      },
      "id": "nceqdadgnW7P",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-10a799fea000>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Fit the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mcheck_X_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    903\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[36. 48. 38. ... 29. 37. 31.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# Define your features (X) and target variable (y)\n",
        "X = df['age']\n",
        "y = df['method']\n",
        "# Assuming you have your data loaded into X (features) and y (target variable)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create a classification tree model\n",
        "classification_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "classification_tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "tynAEHAZ0LLb",
        "outputId": "bdd1671a-0d71-417e-e5f1-012777247729"
      },
      "id": "tynAEHAZ0LLb",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'method'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-11a7ac7a4336>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define your features (X) and target variable (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Assuming you have your data loaded into X (features) and y (target variable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'method'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a",
      "metadata": {
        "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a"
      },
      "source": [
        "**Q4.** This is a question where we use regression and regression trees. The outcome is whether a defendant is held pre-trial in the Virginia justice system. We would like to understand how that outcome is predicted by characteristics of the defendant, particularly race. Let's be very careful/clear: We aren't saying anyone *should* be held without bond or asserting that people with different demographic variables *should* be more likely to be held, but instead trying to predict whether people with different characteristics *are empirically more likely* to be held without bond, given the available information. This is the first step we would take in investigating whether a system is fair, or how large the disparities are: Does it treat people with similar observable characteristics similarly, or not? We are going to look at a common question: Are Black defendants treated differently from white or Asian ones? (There are Native American defendants, but there are 11 in total, which is such a small number of observations that is difficult to clearly say anything about how this group is treated relative to the others.)\n",
        "\n",
        "The variables in the data are:\n",
        "\n",
        "  - `held_wo_bail`: Whether a defendant is held without bail before trial (Boolean logical)\n",
        "  - `race`, `sex`: Categorical demographic variables\n",
        "  - `is_poor`: Whether the defendant is classified as indigent\n",
        "  - `prior_F`, `prior_M`: The number of prior felony and misdemeanor arrests\n",
        "  - `case_type`: A categorical variable indicating a misdemeanor `M` or felony `F` or infraction `I` or special case `S`\n",
        "  - `age`: Defendant's age\n",
        "  - `bond`, `bond_NA`, `bond_type`: The amount of any bond, whether it is missing, and the type\n",
        "  - `sentence`, `sentence_NA`, `sentence_type`: The length of any sentence, whether it is missing, and the type\n",
        "\n",
        "1. Load the `pretrial_data.csv` data. Notice that there are `nan`s, but the data are relatively clean. Because there are `.nan`s among variables you won't use, you'll want to narrow down your analysis to the relevant variables before dropping or imputing missing values.\n",
        "2. Create a dummy variable indicating that the defendant is Black.\n",
        "3. Regress `held` on `Black`. What is the slope coefficient Interpret the coefficient on the Black dummy variable: How much more likely is a black person to be held without bail? What is the $R^2$ of the model?\n",
        "4. Before doing this question, please think for a few minutes about how to make the process of running these regressions as efficient as possible, before jumping into writing code. Repeat part 2, for the following specifications, keeping track of the coefficient on the Black dummy variable each time:\n",
        "      - `held` on `Black` and `sex`\n",
        "      - `held` on `Black` and `sex` and `is_poor`\n",
        "      - `held` on `Black` and `sex` and `is_poor` and `prior_F`\n",
        "      - `held` on `Black` and `sex` and `is_poor` and `prior_F` and `case_type`\n",
        "What happens to the coefficient on the Black dummy variable as you include more regressors/features/controls in the regression? Explain your findings.\n",
        "5. Suppose we don't want to see just `Black` and `sex`, but `Black` interacted with `sex`: Are Black men and Black women treated systemically differently from the rest of the population? Implement this in a regression, and explain your findings.\n",
        "6. Imagine someone argued we should use these kinds of models to help a judge or magistrate make bail decisions (you could obviously go back and make this kind of model for the bond and sentence variables, then deploy it on new cases to predict what their bond and sentence values would be). What concerns would you have? Do you think society should be using data-driven and automated tools like that? Explain your concerns clearly."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LscfohoRj2Ya",
        "outputId": "dfc70691-b379-4103-829a-8642848912d3"
      },
      "id": "LscfohoRj2Ya",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/pretrial_data (1).csv')\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Y023-5x5qzWo",
        "outputId": "decbfd0e-1604-4084-8139-c93270e87033"
      },
      "id": "Y023-5x5qzWo",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0           age       is_poor           bond     bond_type  \\\n",
              "count  22986.00000  22930.000000  21965.000000   16912.000000  22986.000000   \n",
              "mean   11492.50000     34.278020      0.476440    1464.159413      3.113330   \n",
              "std     6635.63098     12.466248      0.499456    2923.362046      1.866408   \n",
              "min        0.00000     18.000000      0.000000       0.000000      1.000000   \n",
              "25%     5746.25000     24.000000      0.000000       0.000000      1.000000   \n",
              "50%    11492.50000     31.000000      0.000000    1000.000000      3.000000   \n",
              "75%    17238.75000     42.000000      1.000000    2500.000000      4.000000   \n",
              "max    22985.00000    100.000000      1.000000  160000.000000      9.000000   \n",
              "\n",
              "            prior_F       prior_M          gini      released  sentence_type  \\\n",
              "count  22501.000000  22501.000000  22972.000000  22955.000000   22712.000000   \n",
              "mean       1.375983      2.692991      0.440635      0.834415       1.815912   \n",
              "std        3.489802      4.438524      0.041939      0.371716       1.799287   \n",
              "min        0.000000      0.000000      0.370000      0.000000       0.000000   \n",
              "25%        0.000000      0.000000      0.420000      1.000000       0.000000   \n",
              "50%        0.000000      1.000000      0.430000      1.000000       1.000000   \n",
              "75%        1.000000      4.000000      0.470000      1.000000       4.000000   \n",
              "max      119.000000     74.000000      0.550000      1.000000       4.000000   \n",
              "\n",
              "           sentence  \n",
              "count  22712.000000  \n",
              "mean      12.207737  \n",
              "std       50.725352  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        5.000000  \n",
              "max     2208.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28c0a128-84e8-453c-af17-9a8559d3a94f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>is_poor</th>\n",
              "      <th>bond</th>\n",
              "      <th>bond_type</th>\n",
              "      <th>prior_F</th>\n",
              "      <th>prior_M</th>\n",
              "      <th>gini</th>\n",
              "      <th>released</th>\n",
              "      <th>sentence_type</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22986.00000</td>\n",
              "      <td>22930.000000</td>\n",
              "      <td>21965.000000</td>\n",
              "      <td>16912.000000</td>\n",
              "      <td>22986.000000</td>\n",
              "      <td>22501.000000</td>\n",
              "      <td>22501.000000</td>\n",
              "      <td>22972.000000</td>\n",
              "      <td>22955.000000</td>\n",
              "      <td>22712.000000</td>\n",
              "      <td>22712.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>11492.50000</td>\n",
              "      <td>34.278020</td>\n",
              "      <td>0.476440</td>\n",
              "      <td>1464.159413</td>\n",
              "      <td>3.113330</td>\n",
              "      <td>1.375983</td>\n",
              "      <td>2.692991</td>\n",
              "      <td>0.440635</td>\n",
              "      <td>0.834415</td>\n",
              "      <td>1.815912</td>\n",
              "      <td>12.207737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6635.63098</td>\n",
              "      <td>12.466248</td>\n",
              "      <td>0.499456</td>\n",
              "      <td>2923.362046</td>\n",
              "      <td>1.866408</td>\n",
              "      <td>3.489802</td>\n",
              "      <td>4.438524</td>\n",
              "      <td>0.041939</td>\n",
              "      <td>0.371716</td>\n",
              "      <td>1.799287</td>\n",
              "      <td>50.725352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5746.25000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11492.50000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17238.75000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2500.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.470000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>22985.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2208.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28c0a128-84e8-453c-af17-9a8559d3a94f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28c0a128-84e8-453c-af17-9a8559d3a94f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28c0a128-84e8-453c-af17-9a8559d3a94f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a12d2c3-d0c9-40e3-804c-9c5dccfe3033\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a12d2c3-d0c9-40e3-804c-9c5dccfe3033')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a12d2c3-d0c9-40e3-804c-9c5dccfe3033 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0S8dB0DuxNR"
      },
      "id": "v0S8dB0DuxNR",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_black'] = (df['race'] == 'Black').astype(int)"
      ],
      "metadata": {
        "id": "nxTExTQQrOWw"
      },
      "id": "nxTExTQQrOWw",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "# Add a constant term to the independent variable\n",
        "X = sm.add_constant(df['is_black'])\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['held_wo_bail']\n",
        "\n",
        "# Fit a linear regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())\n",
        "\n",
        "#What is the slope coefficient Interpret the coefficient on the Black dummy variable?\n",
        "# 0.2590\n",
        "# How much more likely is a black person to be held without bail? What is the  R2  of the model?\n",
        "# The R squared value is 0 and a black person is 89 times more likely to be held without bail"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry79md7srYHs",
        "outputId": "9b0b34f5-6c1f-4323-87b5-c3cf14637514"
      },
      "id": "Ry79md7srYHs",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           held_wo_bail   R-squared:                       0.000\n",
            "Model:                            OLS   Adj. R-squared:                  0.000\n",
            "Method:                 Least Squares   F-statistic:                       nan\n",
            "Date:                Sun, 05 Nov 2023   Prob (F-statistic):                nan\n",
            "Time:                        23:11:02   Log-Likelihood:                -13643.\n",
            "No. Observations:               22984   AIC:                         2.729e+04\n",
            "Df Residuals:                   22983   BIC:                         2.730e+04\n",
            "Df Model:                           0                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.2590      0.003     89.630      0.000       0.253       0.265\n",
            "is_black            0          0        nan        nan           0           0\n",
            "==============================================================================\n",
            "Omnibus:                     4989.398   Durbin-Watson:                   1.641\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5233.828\n",
            "Skew:                           1.100   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.210   Cond. No.                          inf\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/regression/linear_model.py:1965: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "df['is_black'] = (df['race'] == 'Black').astype(int)\n",
        "df['is_female'] = (df['sex'] == 'F').astype(int)\n",
        "\n",
        "# Add a constant term to the independent variables\n",
        "X = sm.add_constant(df[['is_black', 'is_female']])\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['held_wo_bail']\n",
        "\n",
        "# Fit a multiple regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhwN7Lg7sk8l",
        "outputId": "b8ec372e-8695-4c62-f2b9-81d799cfc52f"
      },
      "id": "yhwN7Lg7sk8l",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           held_wo_bail   R-squared:                       0.000\n",
            "Model:                            OLS   Adj. R-squared:                  0.000\n",
            "Method:                 Least Squares   F-statistic:                       nan\n",
            "Date:                Sun, 05 Nov 2023   Prob (F-statistic):                nan\n",
            "Time:                        23:12:14   Log-Likelihood:                -13643.\n",
            "No. Observations:               22984   AIC:                         2.729e+04\n",
            "Df Residuals:                   22983   BIC:                         2.730e+04\n",
            "Df Model:                           0                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.2590      0.003     89.630      0.000       0.253       0.265\n",
            "is_black            0          0        nan        nan           0           0\n",
            "is_female           0          0        nan        nan           0           0\n",
            "==============================================================================\n",
            "Omnibus:                     4989.398   Durbin-Watson:                   1.641\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5233.828\n",
            "Skew:                           1.100   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.210   Cond. No.                          inf\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/regression/linear_model.py:1965: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['is_black'] = (df['race'] == 'Black').astype(int)\n",
        "df['is_female'] = (df['sex'] == 'F').astype(int)\n",
        "df['is_poor'] = df['is_poor'].astype(int)\n",
        "\n",
        "# Add a constant term to the independent variables\n",
        "X = sm.add_constant(df[['is_black', 'is_female', 'is_poor']])\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['held_wo_bail']\n",
        "\n",
        "# Fit a multiple regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su2Pah1Gwku8",
        "outputId": "d0a6f680-4dcf-4332-fdf2-98291c7faf0c"
      },
      "id": "Su2Pah1Gwku8",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           held_wo_bail   R-squared:                       0.045\n",
            "Model:                            OLS   Adj. R-squared:                  0.045\n",
            "Method:                 Least Squares   F-statistic:                     1087.\n",
            "Date:                Sun, 05 Nov 2023   Prob (F-statistic):          6.61e-233\n",
            "Time:                        23:18:35   Log-Likelihood:                -13112.\n",
            "No. Observations:               22984   AIC:                         2.623e+04\n",
            "Df Residuals:                   22982   BIC:                         2.625e+04\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.1739      0.004     45.449      0.000       0.166       0.181\n",
            "is_black            0          0        nan        nan           0           0\n",
            "is_female           0          0        nan        nan           0           0\n",
            "is_poor        0.1869      0.006     32.966      0.000       0.176       0.198\n",
            "==============================================================================\n",
            "Omnibus:                     4092.551   Durbin-Watson:                   1.696\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4493.666\n",
            "Skew:                           1.023   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.289   Cond. No.                          inf\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/regression/linear_model.py:1965: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df['is_black'] = (df['race'] == 'Black').astype(int)\n",
        "df['is_female'] = (df['sex'] == 'F').astype(int)\n",
        "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['prior_M'])\n",
        "df['is_poor'] = df['is_poor'].astype(int)\n",
        "df['prior_M'] = df['prior_M'].astype(int)\n",
        "\n",
        "# Add a constant term to the independent variables\n",
        "X = sm.add_constant(df[['is_black', 'is_female', 'is_poor', 'prior_M']])\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['held_wo_bail']\n",
        "\n",
        "# Fit a multiple regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS02RviQt8v7",
        "outputId": "79ab364c-c098-45e4-e8ca-8a143385ae41"
      },
      "id": "vS02RviQt8v7",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           held_wo_bail   R-squared:                       0.085\n",
            "Model:                            OLS   Adj. R-squared:                  0.085\n",
            "Method:                 Least Squares   F-statistic:                     1044.\n",
            "Date:                Sun, 05 Nov 2023   Prob (F-statistic):               0.00\n",
            "Time:                        23:21:03   Log-Likelihood:                -12439.\n",
            "No. Observations:               22501   AIC:                         2.488e+04\n",
            "Df Residuals:                   22498   BIC:                         2.491e+04\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.1339      0.004     33.015      0.000       0.126       0.142\n",
            "is_black   -1.155e-16   4.37e-18    -26.435      0.000   -1.24e-16   -1.07e-16\n",
            "is_female           0          0        nan        nan           0           0\n",
            "is_poor        0.1572      0.006     27.667      0.000       0.146       0.168\n",
            "prior_M        0.0205      0.001     32.109      0.000       0.019       0.022\n",
            "==============================================================================\n",
            "Omnibus:                     3215.166   Durbin-Watson:                   1.732\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3781.338\n",
            "Skew:                           0.959   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.403   Cond. No.                     1.45e+20\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 2.91e-35. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df['is_black'] = (df['race'] == 'Black').astype(int)\n",
        "df['is_female'] = (df['sex'] == 'F').astype(int)\n",
        "df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=['prior_M'])\n",
        "df['is_poor'] = df['is_poor'].astype(int)\n",
        "df['prior_M'] = df['prior_M'].astype(int)\n",
        "df['is_felony'] = (df['case_type'] == 'F').astype(int)\n",
        "\n",
        "# Add a constant term to the independent variables\n",
        "X = sm.add_constant(df[['is_black', 'is_female', 'is_poor', 'prior_M', 'is_felony']])\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['held_wo_bail']\n",
        "\n",
        "# Fit a multiple regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wUX2k1UuwHg",
        "outputId": "f31fdf2c-3ee8-4d59-9b04-5121e1f6175f"
      },
      "id": "6wUX2k1UuwHg",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           held_wo_bail   R-squared:                       0.241\n",
            "Model:                            OLS   Adj. R-squared:                  0.241\n",
            "Method:                 Least Squares   F-statistic:                     2382.\n",
            "Date:                Sun, 05 Nov 2023   Prob (F-statistic):               0.00\n",
            "Time:                        23:21:21   Log-Likelihood:                -10334.\n",
            "No. Observations:               22501   AIC:                         2.068e+04\n",
            "Df Residuals:                   22497   BIC:                         2.071e+04\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0593      0.004     15.373      0.000       0.052       0.067\n",
            "is_black     1.13e-17   1.17e-18      9.620      0.000       9e-18    1.36e-17\n",
            "is_female   8.795e-19   1.72e-18      0.511      0.609   -2.49e-18    4.25e-18\n",
            "is_poor        0.0777      0.005     14.643      0.000       0.067       0.088\n",
            "prior_M        0.0171      0.001     29.249      0.000       0.016       0.018\n",
            "is_felony      0.3871      0.006     68.040      0.000       0.376       0.398\n",
            "==============================================================================\n",
            "Omnibus:                     1536.787   Durbin-Watson:                   1.871\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1876.624\n",
            "Skew:                           0.707   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.979   Cond. No.                     3.26e+17\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 5.81e-30. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Create interaction terms between 'Black' and 'sex'\n",
        "df['Black_sex_interaction'] = df['is_black'] * df['sex']\n",
        "\n",
        "# Add a constant term to the independent variables\n",
        "X = sm.add_constant(df[['is_black', 'sex', 'Black_sex_interaction']])\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['held_wo_bail']\n",
        "\n",
        "# Fit a regression model with interaction terms\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRt3rcq0y7cB",
        "outputId": "ca8becfb-0877-4045-e3d4-101ab63228a6"
      },
      "id": "NRt3rcq0y7cB",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           held_wo_bail   R-squared:                       0.011\n",
            "Model:                            OLS   Adj. R-squared:                  0.011\n",
            "Method:                 Least Squares   F-statistic:                     255.6\n",
            "Date:                Sun, 05 Nov 2023   Prob (F-statistic):           3.24e-57\n",
            "Time:                        23:23:20   Log-Likelihood:                -13311.\n",
            "No. Observations:               22501   AIC:                         2.663e+04\n",
            "Df Residuals:                   22499   BIC:                         2.664e+04\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=========================================================================================\n",
            "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "const                     0.2907      0.003     84.826      0.000       0.284       0.297\n",
            "is_black                       0          0        nan        nan           0           0\n",
            "sex                      -0.1042      0.007    -15.987      0.000      -0.117      -0.091\n",
            "Black_sex_interaction          0          0        nan        nan           0           0\n",
            "==============================================================================\n",
            "Omnibus:                     4982.162   Durbin-Watson:                   1.652\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4855.684\n",
            "Skew:                           1.062   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.183   Cond. No.                          inf\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/regression/linear_model.py:1965: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine someone argued we should use these kinds of models to help a judge or magistrate make bail decisions (you could obviously go back and make this kind of model for the bond and sentence variables, then deploy it on new cases to predict what their bond and sentence values would be). What concerns would you have? Do you think society should be using data-driven and automated tools like that? Explain your concerns clearly.\n",
        "\n",
        "I think that every data driven device is sucesptible to bias and issues. Data-driven tools can inherit biases present in historical data, which may perpetuate existing disparities in the justice system. This raises concerns about fairness and the potential for discriminatory outcomes.However, there is the usefulness of technological advances when it comes to how quckly and efficiently data driven and automized tools can be used."
      ],
      "metadata": {
        "id": "9-aN1RuE1KUp"
      },
      "id": "9-aN1RuE1KUp"
    },
    {
      "cell_type": "markdown",
      "id": "d0bedb79-b3d9-4db3-9b30-b92c9b618cec",
      "metadata": {
        "id": "d0bedb79-b3d9-4db3-9b30-b92c9b618cec"
      },
      "source": [
        "**Q5.** This is a math question to review the derivation of the OLS estimator (but only if you are into that kind of thing!). We are going to do it slightly differently from what we did in class, though. We will use a linear predictor and minimize the Sum of Squared Errors, just as in class. But, we are going to de-mean $X$ first, creating another variable $z_i = x_i - \\bar{x}$ where\n",
        "$$\n",
        "\\bar{x} = \\dfrac{1}{N} \\sum_{i=1}^N x_i,\n",
        "$$\n",
        "so the model is $\\hat{y}_i = a + b z_i$ and the `SSE` is\n",
        "$$\n",
        "\\text{SSE}(a,b) = \\sum_{i=1}^N (y_i - a - bz_i)^2.\n",
        "$$\n",
        "\n",
        "  1. Take partial derivatives of the `SSE` with respect to $a$ and $b$. You should get\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\sum_{i=1}^N -2(y_i - a- bz_i) &=& 0 \\\\\n",
        "\\sum_{i=1}^N -2(y_i - a - bz_i)z_i &=& 0.\n",
        "\\end{eqnarray*}\n",
        "\n",
        "  2. Solve for the solutions to the above equations. Big hint: $\\bar{z} = 0$, since we subtracted the mean of $x$ from $x$ to get $z$. You should get\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "a^* &=& \\bar{y} \\\\\n",
        "b^* &=& \\dfrac{\\sum_{i=1}^N(y_i - \\bar{y})z_i}{\\sum_{i=1}^N z_i^2}.\n",
        "\\end{eqnarray*}\n",
        "\n",
        "  3. Substitute $z_i = x_i - \\bar{x}$ back into the above equations. You should get\n",
        "  \n",
        "\\begin{eqnarray*}\n",
        "a^* &=& \\bar{y} \\\\\n",
        "b^* &=& \\dfrac{\\sum_{i=1}^N(y_i - \\bar{y})(x_i-\\bar{x})}{\\sum_{i=1}^N (x_i-\\bar{x})^2},\n",
        "\\end{eqnarray*}\n",
        "\n",
        "which can be written in terms of sample covariance and sample variance as:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "a^* &=& \\bar{y} \\\\\n",
        "b^* &=& \\dfrac{\\text{cov}(x,y)}{\\text{var}(x)}.\n",
        "\\end{eqnarray*}\n",
        "\n",
        "This is typically the preferred way of expressing the OLS coefficients.\n",
        "\n",
        "4. When will $b^*$ be large or small, depending on the relationship between $x$ and $y$ and the amount of \"noise\"/variance in $x$? What does $a^*$ represent?\n",
        "5. Suppose you have measurement error in $x$ which artificially inflates its variance (e.g. bad data cleaning). What happens to the $b^*$ coefficient? How will affect your ability to predict? (This phenomenon is called **attenuation**.)\n",
        "6. Let's return to the question of *outliers*. With your formula for the OLS coefficients $(a^*,b^*)$, explain what happens if you significantly increase a single value of the outcome/target/response variable $y_i$ or one of the predictor/explanatory/covariate variables $x_i$. If values for some extreme observations are exerting significant influence over the regression coefficients, will the model perform well on for more average observations?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}